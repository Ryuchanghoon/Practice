{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WTqf5XoaEHQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a92fcb-aefe-4e43-f99b-267e4cbb8caa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tutorial-Book-Utils'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 45 (delta 18), reused 17 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (45/45), 11.62 KiB | 11.62 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dZxoBIWmbuF-Oy_XZoS1z9EjPJwkTmy6\n",
            "To: /content/Victorian400-GAN-colorization-data.zip\n",
            "100% 508M/508M [00:02<00:00, 192MB/s]\n",
            "Victorian400-GAN-colorization-data.zip download complete!\n",
            "unzip:  cannot find or open Victorian400-GAN-colorization-data.zip}, Victorian400-GAN-colorization-data.zip}.zip or Victorian400-GAN-colorization-data.zip}.ZIP.\n"
          ]
        }
      ],
      "source": [
        "## Victorian400 데이터셋 다운 후 압축 해제\n",
        "\n",
        "!git clone https://github.com/Pseudo-Lab/Tutorial-Book-Utils\n",
        "!python Tutorial-Book-Utils/PL_data_loader.py --data GAN-Colorization\n",
        "!unzip -q Victorian400-GAN-colorization-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "# 위에까지 경로지정.\n",
        "\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image # 이미지 파일 시각화.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable # 미분하는 거. 요새는 그냥 내장되어 있어서 굳이 안씀.\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "Hdg_s3OlEuM_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VictorianDataset(Dataset):\n",
        "  def __init__(self, root, color_transforms_ = None, gray_transforms_ = None):\n",
        "\n",
        "    self.color_transforms = transforms.Compose(color_transforms_)\n",
        "    self.gray_transforms = transforms.Compose(gray_transforms_)\n",
        "    self.gray_files = sorted(glob.glob(os.path.join('/content/gray') + '/*.*'))\n",
        "    self.color_files = sorted(glob.glob(os.path.join('/content/resized') + '/*.*'))\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    gray_img = Image.open(self.gray_files[index % len(self.gray_files)]).convert('L') # 흑백 이미지 convert로 1채널로 받아주고,\n",
        "    color_img = Image.open(self.color_files[index % len(self.color_files)]).convert('RGB') # 컬러는 3채널 값으로.\n",
        "\n",
        "\n",
        "    gray_img = self.gray_transforms(gray_img)\n",
        "    color_img = self.color_transforms(color_img)\n",
        "\n",
        "\n",
        "    return {'A' : gray_img, 'B': color_img}\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.gray_files)"
      ],
      "metadata": {
        "id": "WmCZyCqnawt-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = ''\n",
        "test_root = root + 'test/'\n",
        "\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "\n",
        "batch_size = 12\n",
        "test_batch_size = 6\n",
        "\n",
        "gpu = 0"
      ],
      "metadata": {
        "id": "4hriv8jD3PH9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 이전 코드 실습값 갖고 온거.\n",
        "color_mean = [0.58090717, 0.52688643, 0.45678478]\n",
        "color_std = [0.25644188, 0.25482641, 0.24456465]\n",
        "gray_mean = [0.5350533]\n",
        "gray_std = [0.25051587]\n",
        "\n",
        "\n",
        "color_transforms_ = [\n",
        "    transforms.Resize(size = (img_height, img_width)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = color_mean, std = color_std),\n",
        "]\n",
        "\n",
        "gray_transforms_ = [\n",
        "    transforms.Resize(size = (img_height, img_width)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = gray_mean, std = gray_std),\n",
        "]"
      ],
      "metadata": {
        "id": "Rj1iAYDujtgs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### train 로더\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    VictorianDataset(root, color_transforms_ = color_transforms_, gray_transforms_ = gray_transforms_),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "NZXd_JJAkcay",
        "outputId": "022e4ca8-2acf-4576-9e8c-426934f3098f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e667e3f7e993>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### train 로더\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_loader = DataLoader(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mVictorianDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_transforms_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_transforms_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray_transforms_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgray_transforms_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 데이터 잘 되어있는지 확인 작업.\n",
        "\n",
        "def reNormalize(img, mean, std):\n",
        "  img = img.numpy().transpose(1, 2, 0)\n",
        "  img = img * std + mean\n",
        "  img = img.clip(0, 1)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "EbxYkXw2lj19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (10, 5))\n",
        "rows = 1\n",
        "cols = 2\n",
        "\n",
        "for X in train_loader:\n",
        "\n",
        "  print(X['A'].shape, X['B'].shape)\n",
        "\n",
        "  ax1 = fig.add_subplot(rows, cols, 1)\n",
        "  ax1.imshow(reNormalize(X['A'][0], gray_mean, gray_std).reshape(img_height, img_width), cmap = 'gray')\n",
        "  ax1.set_title('gray img')\n",
        "\n",
        "  ax2 = fig.add_subplot(rows, cols, 2)\n",
        "  ax2.imshow(reNormalize(X['B'][0], color_mean, color_std))\n",
        "  ax2.set_title('color img')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "id": "Olx55InonKLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### test 로더\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    VictorianDataset(test_root, color_transforms_= color_transforms_, gray_transforms_ = gray_transforms_),\n",
        "    batch_size = test_batch_size,\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "q4BmPgBEnwFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (10, 5))\n",
        "rows = 1\n",
        "cols = 2\n",
        "\n",
        "for X in test_loader:\n",
        "\n",
        "  print(X['A'].shape, X['B'].shape)\n",
        "  ax1 = fig.add_subplot(rows, cols, 1)\n",
        "  ax1.imshow(reNormalize(X['A'][0], gray_mean, gray_std).reshape(img_height, img_width), cmap = 'gray')\n",
        "  ax1.set_title('gray img')\n",
        "\n",
        "  ax2 = fig.add_subplot(rows, cols, 2)\n",
        "  ax2.imshow(reNormalize(X['B'][0], color_mean, color_std))\n",
        "  ax2.set_title('color img')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "id": "zjJK4hdZoTr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### GAN 모델 구축."
      ],
      "metadata": {
        "id": "W5YBEQfvrmkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels= 2, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.BatchNorm2d(64), # 출력 채널에 맞춰서.\n",
        "        nn.LeakyReLU(0.1), # LeakyReLU가 입력값이 0보다 크면, 그대로, 0보다 작음 0.1 곱해서. 그래프 떠올려보자.\n",
        "    )\n",
        "\n",
        "    self.maxpool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 64, out_channels = 64 * 2, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.1)\n",
        "    )\n",
        "\n",
        "    self.upsample = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels = 64 * 2, out_channels = 64, kernel_size = 4, stride = 2, padding = 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "    self.conv1by1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 1, stride = 1, padding = 0),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.1)\n",
        "    )\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 64, out_channels = 3, kernel_size = 3, stride = 1, padding = 1),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    output1 = self.conv1(input)\n",
        "\n",
        "    pool1 = self.maxpool(output1)\n",
        "    output2 = self.conv2(pool1)\n",
        "    output3 = self.upsample(output2) + output1\n",
        "    output4 = self.conv1by1(output3)\n",
        "\n",
        "    out = self.conv(output4)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "GeK8sl00rtp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.main = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 3, out_channels = )\n",
        "    )"
      ],
      "metadata": {
        "id": "LjQojIbLS-IN"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}