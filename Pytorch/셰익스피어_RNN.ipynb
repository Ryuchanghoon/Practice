{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kH2qejYVlac",
        "outputId": "93693a76-7f77-4f50-87c5-cecc4a2a088a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-09 02:16:05--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘./data/input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-05-09 02:16:06 (32.7 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    os.mkdir(\"./data\")\n",
        "\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "SRKi9Ym2WBHP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5ICxLX3WnBF",
        "outputId": "9ba0a2c3-7442-44f6-bcb1-cf291022b1b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math"
      ],
      "metadata": {
        "id": "z2G30ABfWrkV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "\n",
        "chunk_len = 200\n",
        "\n",
        "hidden_size = 200\n",
        "batch_size = 1\n",
        "num_layers = 1\n",
        "embedding_size = 70\n",
        "lr = 0.002"
      ],
      "metadata": {
        "id": "-jk2hDMDW1NV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = string.printable #위에 import 해준거 all_characters로 받아주고,\n",
        "\n",
        "n_characters = len(all_characters) \n",
        "print(all_characters)\n",
        "print('num_chars = ', n_characters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DleuVNWXjbV",
        "outputId": "c5b68028-f12a-4e55-b34e-2545d5df68d3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars =  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = unidecode.unidecode(open('./data/input.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len) #총 1115394개의 문자"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMH6qTAToYZk",
        "outputId": "74f385de-3b9d-44ac-fd92-7697bee6b76b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_len = 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_chunck():\n",
        "    start_index = random.randint(0, file_len - chunk_len) # 전체 파일에서 200개 빼준거, start_index로\n",
        "    end_index = start_index + chunk_len + 1 # start_index 받아준거에서 그 이후꺼.\n",
        "    \n",
        "    return file[start_index : end_index]\n",
        "\n",
        "print(random_chunck())\n",
        " #값은 랜덤하게 불러와서 맨날 바뀜."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH9XHYmIoxZb",
        "outputId": "91dd3eaa-f33b-4bac-9a5e-058d85246793"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":\n",
            "Very well; and could be content to give him good\n",
            "report fort, but that he pays himself with being proud.\n",
            "\n",
            "Second Citizen:\n",
            "Nay, but speak not maliciously.\n",
            "\n",
            "First Citizen:\n",
            "I say unto you, what he hath \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#문자열을 인덱스로 반환하는 함수.\n",
        "\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long() #string길이만큼 0으로 채우고, 100개.\n",
        "    \n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c]) #반복문 돌면서 0 아닌 값으로 채워넣기.\n",
        "    return tensor\n",
        "\n",
        "print(char_tensor('ABCdef')) #이놈들이 몇번째인지 확인."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq-aOUNLqPLb",
        "outputId": "d6130c14-5a5e-4b38-ff17-c94a2f36f805"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_training_set():\n",
        "    chunck = random_chunck()\n",
        "    inp = char_tensor(chunck[: -1]) #맨 뒷글자 빼고 전부.\n",
        "    target = char_tensor(chunck[1:]) #2번째 글자부터.\n",
        "    # ex) 문자 ryuch이면, 첨에 ryuc입력, 목표(타겟)값은 yuch. 이런 느낌.\n",
        "    return inp, target"
      ],
      "metadata": {
        "id": "xeIj-osprkmy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers = 1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.encoder = nn.Embedding(self.input_size, self.embedding_size) # 임베딩 작업 수행.(어떤 확률값으로 바꾸고)\n",
        "        \n",
        "        self.rnn = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers) \n",
        "        \n",
        "        self.decoder = nn.Linear(self.hidden_size, self.output_size) # 임베딩 작업 후 나온 확률값 바탕으로 출력 시퀀스 생성.\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        out = self.encoder(input.view(1, -1))\n",
        "        out, hidden = self.rnn(out, hidden)\n",
        "        out = self.decoder(out.view(batch_size, -1)) #view가 텐서 크기 변경하는 함수.\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return hidden\n",
        "\n",
        "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"
      ],
      "metadata": {
        "id": "9UwMQEQJu82J"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(input_size = n_characters,\n",
        "            embedding_size = embedding_size,\n",
        "            hidden_size = hidden_size,\n",
        "            output_size = n_characters,\n",
        "            num_layers = 2)"
      ],
      "metadata": {
        "id": "3m2apWN7yMnV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = char_tensor('A') #아까 위에서 선언 해준것. (문자열 인덱스로 바꾸는 것.)\n",
        "print(inp)\n",
        "\n",
        "hidden = model.init_hidden() #은닉층 거쳐서 초기화\n",
        "print(hidden.size())\n",
        "\n",
        "out, hidden = model(inp, hidden) #rnn 돌고 은닉층 거치고.\n",
        "print(out.size())"
      ],
      "metadata": {
        "id": "gx0n7phuznjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd5df68-e3c9-4e52-c7c2-5517f2d1062a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36])\n",
            "torch.Size([2, 1, 200])\n",
            "torch.Size([1, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "9gtuYD7A0Dp9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden = model.init_hidden()\n",
        "    x = inp\n",
        "\n",
        "    print(start_str, end=\"\")\n",
        "    for i in range(200):\n",
        "        output,hidden = model(x, hidden)\n",
        "\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0] # 매번 같은 값만 아니고, 랜덤하게 다음 글자 뽑으려고 'multinomial'\n",
        "        predicted_char = all_characters[top_i]\n",
        "\n",
        "        print(predicted_char, end = \"\")\n",
        "\n",
        "        x = char_tensor(predicted_char)"
      ],
      "metadata": {
        "id": "XC95GsBN15Lz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs):\n",
        "    inp, label = random_training_set()\n",
        "    hidden = model.init_hidden()\n",
        "\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for j in range(chunk_len -1):\n",
        "        x = inp[j] #반복문 돌면서 x값으로 넣고,\n",
        "        y_ = label[j].unsqueeze(0).type(torch.LongTensor) #라벨값 가져오고 LongTensor형태로 바꾼 것.\n",
        "        y, hidden = model(x, hidden)\n",
        "        loss += loss_func(y, y_)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n\", loss / chunk_len, '\\m') #loss가 chunk_len(200)만큼 더해져서 이렇게 나눠줌.\n",
        "        test() \n",
        "        print('\\m', '=' * 100)"
      ],
      "metadata": {
        "id": "YQmu8nFB25Ys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae40e796-32b5-4318-9b7e-45ef1df85ade"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " tensor([4.5635], grad_fn=<DivBackward0>) \\m\n",
            "b_f+p]RR{8=\u000bdoo]\rQ*kOc.T_vtdzrTB=b)k_*\\/ImHSZ9.o\f?6F\n",
            "4f*JsT{}1Po]d~t5h.0+2Q6R!uJO\r!yd57x/fv*3NAFX$\\m.\r\u000b$ysr\f\u000b>tk JgItDLE,)bb,.TyO7:v`KP/R)\n",
            "js9*P{Nrh\n",
            "'KQ&Um)N%ZK<?}t\u000bRfD@%Tz6&+\n",
            "iWx 0gi26h\tO*a{GrLM\t\u000b5VRd\\m ====================================================================================================\n",
            "\n",
            " tensor([2.4152], grad_fn=<DivBackward0>) \\m\n",
            "bphad, ihd bewe ylith borl'y Core w?ndl\n",
            "Ancenrls, wouFhoull hane dis wy and the the seas touch Ms wo lis,\n",
            "Sule Whase is wake sarthit ighes ath fand mace ciwher, as his it hirs cnpathe fside were byow, \\m ====================================================================================================\n",
            "\n",
            " tensor([2.5757], grad_fn=<DivBackward0>) \\m\n",
            "bear\n",
            "ouk indy of pobe for bove mind pthes soar proan tou dat; this, bese, my your afe woO\n",
            "The my ind vord agith mise wyoues hat,\n",
            "Thich for sead mothh so sone wim to I mof,\n",
            "Nnd artede of mer mone I ast \\m ====================================================================================================\n",
            "\n",
            " tensor([2.1903], grad_fn=<DivBackward0>) \\m\n",
            "best son\n",
            "That wo'l theace cons chate this oun; your ney seesdongais of ustor whe in that be dodraing\n",
            "Noth\n",
            "Onden sordine,\n",
            "Tak, and'd hour:'d staep, the dright urther ste, me she the matpeace\n",
            "And and sou\\m ====================================================================================================\n",
            "\n",
            " tensor([1.9841], grad_fn=<DivBackward0>) \\m\n",
            "bed;\n",
            "The hat to and of hrike terter here op that the bestons, thy cinsore;\n",
            "That bangisom iot,\n",
            "Thour ourth and me, thy, the dead, the ny with iib, my spownay, my liwill now to Giger Go forser is Goning \\m ====================================================================================================\n",
            "\n",
            " tensor([1.9565], grad_fn=<DivBackward0>) \\m\n",
            "be to hem hinden's his lom!\n",
            "\n",
            "Fendent.\n",
            "\n",
            "Force:\n",
            "De'll de as tone to but a ligh thy mued have in the sthet thing reY what youe fraito he the hour.\n",
            "\n",
            "ERWYOR:\n",
            "For strinn:\n",
            "And playing the must thou he pling h\\m ====================================================================================================\n",
            "\n",
            " tensor([2.0956], grad_fn=<DivBackward0>) \\m\n",
            "ble parded your pay, kir to hath a ross dead horearsave tensersion to there fathard you hat the mly gaths, un it rome it of word, athis no pames both as righers to purth's not father.\n",
            "\n",
            "CARTENARI SIXNIN\\m ====================================================================================================\n",
            "\n",
            " tensor([1.9498], grad_fn=<DivBackward0>) \\m\n",
            "best couring you shouth swacknher have's fare servoses, the pravem sirst me mand is e\n",
            "mer's as yourt than keushs, as, fals, greateds\n",
            "That at, banrice\n",
            "This shiptres than for fuase hus hath for it mike t\\m ====================================================================================================\n",
            "\n",
            " tensor([1.6102], grad_fn=<DivBackward0>) \\m\n",
            "be decomfur our more the ourded sway's with our bite the sentruce, his my she is in the braspilest on meend's seed comy is in nome me asf as bbore sece, what to but down the to mouse now as the hored t\\m ====================================================================================================\n",
            "\n",
            " tensor([1.8129], grad_fn=<DivBackward0>) \\m\n",
            "breas mertsondids I cans?\n",
            "\n",
            "BENTEN:\n",
            "O, I'll As.\n",
            "\n",
            "CLAUDIO:\n",
            "Aod, had drow seasand of, sursess.\n",
            "Save my lastion brievel, Ilaw-;\n",
            "What ferseath.\n",
            "Way: your parvack end her she scome\n",
            "Wather prace:\n",
            "The see fors\\m ====================================================================================================\n",
            "\n",
            " tensor([1.7376], grad_fn=<DivBackward0>) \\m\n",
            "bent of he would it spay we rown and peal the king the priste to prean to best the goxgre\n",
            "To live and betre was be down stroth he stors,\n",
            "I down going's appomen.\n",
            "\n",
            "BUCKARINA:\n",
            "In, no be the bescemply he b\\m ====================================================================================================\n",
            "\n",
            " tensor([1.9547], grad_fn=<DivBackward0>) \\m\n",
            "bed not the smed,\n",
            "And grace.\n",
            "\n",
            "KING RICHARD III\n",
            "And it bey\n",
            "Whom look the wresty lombly heare? Duch vanger'd a fain! fall very of this whou and what I ffilly not of they with all a not, be rive stright J\\m ====================================================================================================\n",
            "\n",
            " tensor([1.5820], grad_fn=<DivBackward0>) \\m\n",
            "bagks, the bid brincer:\n",
            "Now, you narr't well,\n",
            "That reves, acking tongue, and gins know, wid now so pring a will Larnes of mastion fair, may cass of he will be friar:\n",
            "Sir this decomred?\n",
            "\n",
            "GLOUCESTER:\n",
            "O s\\m ====================================================================================================\n",
            "\n",
            " tensor([1.8810], grad_fn=<DivBackward0>) \\m\n",
            "brough bed\n",
            "That you, the in the cones to name lowise, if him.\n",
            "\n",
            "PAUTOLYCUI:\n",
            "We Do North, hook of the ien is laith, by these blood bientites the are of you call the not make in the faith they strid if lo\\m ====================================================================================================\n",
            "\n",
            " tensor([1.7981], grad_fn=<DivBackward0>) \\m\n",
            "blood thy remon thee he be pate,\n",
            "And thou?\n",
            "\n",
            "GARWARD IV:\n",
            "Norked thou would their sitherity, save in the rever;--hrown to mookerst this but should you lozk.\n",
            "\n",
            "PETRUTIO:\n",
            "And it:\n",
            "Here doame,--\n",
            "\n",
            "GLOUCESTER:\n",
            "\\m ====================================================================================================\n",
            "\n",
            " tensor([1.5870], grad_fn=<DivBackward0>) \\m\n",
            "ban his unto then all saving it a was she mid blactor away thou denties it 'tis inly langer his firtar and soul be!\n",
            "To had my cappent be depose his exent hold hemy inlo.\n",
            "In, and heres!\n",
            "\n",
            "This chare she \\m ====================================================================================================\n",
            "\n",
            " tensor([1.9107], grad_fn=<DivBackward0>) \\m\n",
            "band,\n",
            "Or man, I weers to lighter tarnarding plewing us, pill in the weard Buke.\n",
            "\n",
            "BRUMHS:\n",
            "That and you, fornow's and I were whoth he for pune for have with beacted I wanst and full not,\n",
            "Wordden the umbl\\m ====================================================================================================\n",
            "\n",
            " tensor([1.8873], grad_fn=<DivBackward0>) \\m\n",
            "by well'd whose ploody,\n",
            "And City of quise my lide\n",
            "And say but a would your bo you bearenne, am troue with her 'twere in heart, make a marry most and be their procestastius,\n",
            "And they she bating your ber\\m ====================================================================================================\n",
            "\n",
            " tensor([1.7592], grad_fn=<DivBackward0>) \\m\n",
            "briok,\n",
            "And the rock him:\n",
            "O contourse is thy live their monson, to the face!\n",
            "Ovather borse thou karce onesle eveces,\n",
            "And shall fattle a please thy are heant demore,\n",
            "And on the shalt came,\n",
            "All strick al \\m ====================================================================================================\n",
            "\n",
            " tensor([1.8475], grad_fn=<DivBackward0>) \\m\n",
            "by duk ride and not house trues,\n",
            "I chare-ait and tries\n",
            "To\n",
            "me's noble even tumpertin of a shall repatter come that heancy can we speak tost call the sobme this her, trush the busin of should her my broo\\m ====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BMPaywUTXr-0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}