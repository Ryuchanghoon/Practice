{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lGR89BdYxVwR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 35\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "string = \"hello pytorch! hello python\"\n",
        "chars =  \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\""
      ],
      "metadata": {
        "id": "3FsNfdMPx3yx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_list = [i for i in chars]\n",
        "n_letters = len(char_list)"
      ],
      "metadata": {
        "id": "mRyn-lClx9hr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(n_letters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wPEfJoCyJMF",
        "outputId": "0f4067f6-0d38-49be-ce24-ded82a024abf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원핫 인코더\n",
        "def string_to_onehot(string):\n",
        "    start = np.zeros(shape = n_letters, dtype = int)\n",
        "    end = np.zeros(shape = n_letters, dtype = int)\n",
        "\n",
        "    start[-2] = 1\n",
        "    end[-1] = 1\n",
        "        #이렇게 해주는 이유가, 전에꺼를 다음꺼로 넘겨주기 위함.\n",
        "    for i in string:\n",
        "        idx = char_list.index(i)\n",
        "        zero = np.zeros(shape = n_letters, dtype = int)\n",
        "        \n",
        "        zero[idx] = 1\n",
        "        start = np.vstack([start, zero])\n",
        "\n",
        "    output = np.vstack([start, end])\n",
        "    return output"
      ],
      "metadata": {
        "id": "I-v39AFUyL_x"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#위에 원핫 만들어준거 다시 문자로 바꾸는 함수 생성.\n",
        "def onehot_to_word(onehot_1):\n",
        "    onehot = torch.Tensor.numpy(onehot_1)\n",
        "    return char_list[onehot.argmax()]"
      ],
      "metadata": {
        "id": "ldV-2dB3zVOn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i20 = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.act_fn = nn.Tanh()\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1) #입력, 은닉층을 합치고,\n",
        "        hidden = self.act_fn(self.i2h(combined)) #이걸 활성화 함수 통과,\n",
        "                                                 \n",
        "        output = self.i20(combined) # 결과값 계산하게끔.\n",
        "        return output, hidden\n",
        "\n",
        "        #은닉층 초기화.\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "rnn = RNN(n_letters, n_hidden, n_letters)"
      ],
      "metadata": {
        "id": "UQP_zSO0zvtD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "4--K6Gec0rvU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n",
        "\n",
        "for i in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    hidden = rnn.init_hidden()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for j in range(one_hot.size()[0] -1): #맨 마지막 글자는 넣을 필요 x 그래서 -1\n",
        "        input_ = one_hot[j:j+1, :]\n",
        "        target = one_hot[j+1]\n",
        "        output, hidden = rnn.forward(input_, hidden)\n",
        "\n",
        "        loss = loss_fn(output.view(-1), target.view(-1))\n",
        "        total_loss += loss\n",
        "\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(total_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_YyLoQ21ivS",
        "outputId": "d9c1a7eb-9191-4293-cb30-c0ca3118e4c5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.2001, grad_fn=<AddBackward0>)\n",
            "tensor(0.2819, grad_fn=<AddBackward0>)\n",
            "tensor(0.1078, grad_fn=<AddBackward0>)\n",
            "tensor(0.0627, grad_fn=<AddBackward0>)\n",
            "tensor(0.0441, grad_fn=<AddBackward0>)\n",
            "tensor(0.0351, grad_fn=<AddBackward0>)\n",
            "tensor(0.0311, grad_fn=<AddBackward0>)\n",
            "tensor(0.0294, grad_fn=<AddBackward0>)\n",
            "tensor(0.0287, grad_fn=<AddBackward0>)\n",
            "tensor(0.0285, grad_fn=<AddBackward0>)\n",
            "tensor(0.0284, grad_fn=<AddBackward0>)\n",
            "tensor(0.0281, grad_fn=<AddBackward0>)\n",
            "tensor(0.0356, grad_fn=<AddBackward0>)\n",
            "tensor(0.0307, grad_fn=<AddBackward0>)\n",
            "tensor(0.0293, grad_fn=<AddBackward0>)\n",
            "tensor(0.0287, grad_fn=<AddBackward0>)\n",
            "tensor(0.0282, grad_fn=<AddBackward0>)\n",
            "tensor(0.0327, grad_fn=<AddBackward0>)\n",
            "tensor(0.0295, grad_fn=<AddBackward0>)\n",
            "tensor(0.0286, grad_fn=<AddBackward0>)\n",
            "tensor(0.0283, grad_fn=<AddBackward0>)\n",
            "tensor(0.0273, grad_fn=<AddBackward0>)\n",
            "tensor(0.0341, grad_fn=<AddBackward0>)\n",
            "tensor(0.0288, grad_fn=<AddBackward0>)\n",
            "tensor(0.0359, grad_fn=<AddBackward0>)\n",
            "tensor(0.0290, grad_fn=<AddBackward0>)\n",
            "tensor(0.0754, grad_fn=<AddBackward0>)\n",
            "tensor(0.0384, grad_fn=<AddBackward0>)\n",
            "tensor(0.0318, grad_fn=<AddBackward0>)\n",
            "tensor(0.0296, grad_fn=<AddBackward0>)\n",
            "tensor(0.0288, grad_fn=<AddBackward0>)\n",
            "tensor(0.0284, grad_fn=<AddBackward0>)\n",
            "tensor(0.0279, grad_fn=<AddBackward0>)\n",
            "tensor(0.0266, grad_fn=<AddBackward0>)\n",
            "tensor(0.0442, grad_fn=<AddBackward0>)\n",
            "tensor(0.0356, grad_fn=<AddBackward0>)\n",
            "tensor(0.0308, grad_fn=<AddBackward0>)\n",
            "tensor(0.0294, grad_fn=<AddBackward0>)\n",
            "tensor(0.0288, grad_fn=<AddBackward0>)\n",
            "tensor(0.0285, grad_fn=<AddBackward0>)\n",
            "tensor(0.0283, grad_fn=<AddBackward0>)\n",
            "tensor(0.0281, grad_fn=<AddBackward0>)\n",
            "tensor(0.0276, grad_fn=<AddBackward0>)\n",
            "tensor(0.0266, grad_fn=<AddBackward0>)\n",
            "tensor(0.0329, grad_fn=<AddBackward0>)\n",
            "tensor(0.0295, grad_fn=<AddBackward0>)\n",
            "tensor(0.0679, grad_fn=<AddBackward0>)\n",
            "tensor(0.0355, grad_fn=<AddBackward0>)\n",
            "tensor(0.0311, grad_fn=<AddBackward0>)\n",
            "tensor(0.0296, grad_fn=<AddBackward0>)\n",
            "tensor(0.0288, grad_fn=<AddBackward0>)\n",
            "tensor(0.0286, grad_fn=<AddBackward0>)\n",
            "tensor(0.0285, grad_fn=<AddBackward0>)\n",
            "tensor(0.0283, grad_fn=<AddBackward0>)\n",
            "tensor(0.0282, grad_fn=<AddBackward0>)\n",
            "tensor(0.0277, grad_fn=<AddBackward0>)\n",
            "tensor(0.0265, grad_fn=<AddBackward0>)\n",
            "tensor(0.0219, grad_fn=<AddBackward0>)\n",
            "tensor(0.0561, grad_fn=<AddBackward0>)\n",
            "tensor(0.0520, grad_fn=<AddBackward0>)\n",
            "tensor(0.0502, grad_fn=<AddBackward0>)\n",
            "tensor(0.0337, grad_fn=<AddBackward0>)\n",
            "tensor(0.0260, grad_fn=<AddBackward0>)\n",
            "tensor(0.0344, grad_fn=<AddBackward0>)\n",
            "tensor(0.0253, grad_fn=<AddBackward0>)\n",
            "tensor(0.0196, grad_fn=<AddBackward0>)\n",
            "tensor(0.0443, grad_fn=<AddBackward0>)\n",
            "tensor(0.0338, grad_fn=<AddBackward0>)\n",
            "tensor(0.0305, grad_fn=<AddBackward0>)\n",
            "tensor(0.0292, grad_fn=<AddBackward0>)\n",
            "tensor(0.0285, grad_fn=<AddBackward0>)\n",
            "tensor(0.0275, grad_fn=<AddBackward0>)\n",
            "tensor(0.0229, grad_fn=<AddBackward0>)\n",
            "tensor(0.0679, grad_fn=<AddBackward0>)\n",
            "tensor(0.0385, grad_fn=<AddBackward0>)\n",
            "tensor(0.0436, grad_fn=<AddBackward0>)\n",
            "tensor(0.0278, grad_fn=<AddBackward0>)\n",
            "tensor(0.0203, grad_fn=<AddBackward0>)\n",
            "tensor(0.0144, grad_fn=<AddBackward0>)\n",
            "tensor(0.0091, grad_fn=<AddBackward0>)\n",
            "tensor(0.0091, grad_fn=<AddBackward0>)\n",
            "tensor(0.0136, grad_fn=<AddBackward0>)\n",
            "tensor(0.0061, grad_fn=<AddBackward0>)\n",
            "tensor(0.0025, grad_fn=<AddBackward0>)\n",
            "tensor(0.0010, grad_fn=<AddBackward0>)\n",
            "tensor(0.0004, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(6.8033e-05, grad_fn=<AddBackward0>)\n",
            "tensor(4.6359e-05, grad_fn=<AddBackward0>)\n",
            "tensor(3.3427e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.5084e-05, grad_fn=<AddBackward0>)\n",
            "tensor(1.9391e-05, grad_fn=<AddBackward0>)\n",
            "tensor(1.5279e-05, grad_fn=<AddBackward0>)\n",
            "tensor(1.2204e-05, grad_fn=<AddBackward0>)\n",
            "tensor(9.8503e-06, grad_fn=<AddBackward0>)\n",
            "tensor(8.0174e-06, grad_fn=<AddBackward0>)\n",
            "tensor(6.5690e-06, grad_fn=<AddBackward0>)\n",
            "tensor(5.4122e-06, grad_fn=<AddBackward0>)\n",
            "tensor(4.4799e-06, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = torch.zeros(1, n_letters)\n",
        "start[:, -2] = 1 # 마지막 문자 다음에 오는 문자를 시작 문자로 지정하려고.\n",
        "\n",
        "with torch.no_grad():\n",
        "    hidden = rnn.init_hidden()\n",
        "    input_ = start #첫 입력으로 start 전달.\n",
        "    output_string = \"\" #나오는 문자 계속 붙여주기.\n",
        "\n",
        "    for i in range(len(string)):\n",
        "        output, hidden = rnn.forward(input_, hidden)\n",
        "        output_string += onehot_to_word(output.data) #위에꺼 누적.\n",
        "        input_ = output #이번 결과값, 다음 입력값으로.\n",
        "\n",
        "print(output_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU1MwBVr2jUE",
        "outputId": "6ee9043c-3543-4dd6-f329-2039bf0a9c5e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello pytorch! hello python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Bel3OLJ3AUs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}